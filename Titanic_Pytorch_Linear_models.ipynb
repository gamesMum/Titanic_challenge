{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Titanic with Pytorch\nHello there! We'll try to solve the Titanic survival model first as a Linear Regression problem and second as classification problem.\n\n- We'll take a look at our data.\n- Choose the features (Featur selection)\n- Creating our custom dataset and batches using Pytorch DataLoader which will make it an easy task.\n\nLet's dive in!","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Import all the necessary libraries\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport torch \nfrom torch import nn \nimport matplotlib.pyplot as plt \nimport torch.optim\nfrom torch.nn import functional as F\nfrom torch.autograd import Variable\nfrom torch.utils.data import TensorDataset, DataLoader, random_split\nfrom numpy import array","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Exploring the data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = pd.read_csv('/kaggle/input/titanic/train.csv')\ntrain_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data = pd.read_csv('/kaggle/input/titanic/test.csv')\ntest_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check the length and columns\nlen(train_data.index)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(train_data.columns)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So after I created the batches I noticed `nan` values in the `Age` column so I went back here and counted how many are there","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check for Nan vlues\nprint(train_data['Age'].isnull().values.sum())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can choose to drop the age from the training or just drop the NAN values.\n\nI chose to execlude it from training.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Find survival rate for women\nwomen = train_data.loc[train_data.Sex=='female'][\"Survived\"]\nrate_women = sum(women) / len(women)\nF\"% of women who survived: {rate_women}\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"men = train_data.loc[train_data.Sex=='male']['Survived']\nmen_rate = sum(men) / len(men)\nF\"% of men who survived: {men_rate}\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Find the survival rate in the different classes\nfare_mean_1st = train_data[train_data[\"Pclass\"]==1].Fare.mean()\nfare_mean_2nd = train_data[train_data[\"Pclass\"]==2].Fare.mean()\nfare_mean_3rd = train_data[train_data[\"Pclass\"]==3].Fare.mean()\nF\"Average cost of tickets for 1st, snd, 3rd classes: \\\n{fare_mean_1st} || {fare_mean_2nd} || {fare_mean_3rd}\"\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now let's see how were the effect of other factors in the rate of survival.\nThe code below might not be the easiest to read, but if we take a second good look it will be clear tp us that we are dividing the numbers of survivals (men/women) by the number of passangers (survived or not) in the specific class.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"woman_survived_1st = len(train_data[(train_data[\"Sex\"]==\"female\") & (train_data[\"Survived\"]==1) & (train_data[\"Pclass\"]==1)].index) / len(train_data[(train_data[\"Sex\"]==\"female\") & (train_data[\"Pclass\"]==1)].index)\nwoman_survived_2nd = len(train_data[(train_data[\"Sex\"]==\"female\") & (train_data[\"Survived\"]==1) & (train_data[\"Pclass\"]==2)].index) / len(train_data[(train_data[\"Sex\"]==\"female\") & (train_data[\"Pclass\"]==2)].index)\nwoman_survived_3rd = len(train_data[(train_data[\"Sex\"]==\"female\") & (train_data[\"Survived\"]==1) & (train_data[\"Pclass\"]==3)].index) / len(train_data[(train_data[\"Sex\"]==\"female\") & (train_data[\"Pclass\"]==3)].index)\n\nF\"Rate of Survival for women in different classes: {woman_survived_1st} || {woman_survived_2nd} || {woman_survived_3rd}\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's find out what other factors could effect the rate of survival\nwoman_survived_1st = len(train_data[(train_data[\"Sex\"]==\"male\") & (train_data[\"Survived\"]==1) & (train_data[\"Pclass\"]==1)].index) / len(train_data[(train_data[\"Sex\"]==\"male\") & (train_data[\"Pclass\"]==1)].index)\nwoman_survived_2nd = len(train_data[(train_data[\"Sex\"]==\"male\") & (train_data[\"Survived\"]==1) & (train_data[\"Pclass\"]==2)].index) / len(train_data[(train_data[\"Sex\"]==\"male\") & (train_data[\"Pclass\"]==2)].index)\nwoman_survived_3rd = len(train_data[(train_data[\"Sex\"]==\"male\") & (train_data[\"Survived\"]==1) & (train_data[\"Pclass\"]==3)].index) / len(train_data[(train_data[\"Sex\"]==\"male\") & (train_data[\"Pclass\"]==3)].index)\n\nF\"Rate of Survival for men in different classes: {woman_survived_1st} || {woman_survived_2nd} || {woman_survived_3rd}\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# The verage Age \nage_mean = train_data.Age.mean()\nsurvived_age_mean = train_data[(train_data[\"Survived\"]==1)].Age.mean()\nsurvived_age_std = train_data[(train_data[\"Survived\"]==1)].Age.std()\nsurvived_min_age = train_data[(train_data[\"Survived\"]==1)].Age.min()\nsurvived_max_age = train_data[(train_data[\"Survived\"]==1)].Age.max()\n\nprint(\"The average of survivals age \", survived_age_mean)\nprint(\"The STD of survivals age \", survived_age_std)\nprint(\"The min age of survivals \", survived_min_age)\nprint(\"The max age of survivals \", survived_max_age)\n\n# Let's see the other side\ndeceased_age_mean = train_data[(train_data[\"Survived\"]==0)].Age.mean()\ndeceased_age_std = train_data[(train_data[\"Survived\"]==0)].Age.std()\ndeceased_min_age = train_data[(train_data[\"Survived\"]==0)].Age.min()\ndeceased_max_age = train_data[(train_data[\"Survived\"]==0)].Age.max()\n\nprint()\nprint(\"The average of deceased age\", deceased_age_mean)\nprint(\"The STD of deceased age\", deceased_age_std)\nprint(\"The min age of deceased \", deceased_min_age)\nprint(\"The max age of deceased \", deceased_max_age)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As you can see we can go forever in exploring the data. Now let's start preparing our data for machine learning.\nwe'll divide our data into features and labels and also into training and testing sets.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Splitting data into labels and targets\nfeatures = [\"Pclass\", \"Sex\", \"Fare\", \"SibSp\", \"Parch\"]\n\n\n# Dividing the data into features and labels\ny= train_data['Survived']\n\n# Convert Sex columns into one hot encoding\nX = pd.get_dummies(train_data[features])\nX_test = pd.get_dummies(test_data[features])\n\n\n# Normalizing the data with min max normalization\nX[\"Fare\"] = (X[\"Fare\"] - X[\"Fare\"].min()) / (X[\"Fare\"].max() - X[\"Fare\"].min())\nX_test[\"Fare\"] = (X_test[\"Fare\"] - X_test[\"Fare\"].min()) / (X_test[\"Fare\"].max() - X_test[\"Fare\"].min())\n       ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# convert to numpy array \nX = X.to_numpy()\ny = y.to_numpy().reshape(-1, 1)\nX_test = X_test.to_numpy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"F\"Length of train data: {len(X)}  Length of test data: {len(X_test)} \"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Chaeck the types of the data and shapes\nprint(\"The type of our data:\\n\", type(X))\nprint(type(X_test))\n\n\n\n# Print the shapes\nprint(\"\\nThe shape of our training data: \\n\", X.shape)\nprint(\"\\nThe shape of our targets: \\n\", y.shape)\nprint(\"\\nThe shape of our test data: \\n\", X_test.shape)\n\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Batching the Data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Batch the data for the linear regression\ndef batch_data(batch_size, input_data, target, test_data, train_type = \"regression\"):\n    '''\n    This function batches the data for our model to train on\n    batch_size: number of batches to perform backpropagation on\n    input_data: numpy array with our input features\n    target: numpy array with our target\n    test_data: numpy array of our test data (doesn't contain targets)\n    train_type: some small differences in batches between regression vs classification\n    '''\n    if train_type == \"regression\":\n         target_tensor = torch.FloatTensor(target)\n            \n    elif train_type == \"classification\":\n        target_tensor = torch.LongTensor(target)\n        target_tensor = target_tensor.squeeze()\n        \n    input_tensor = torch.FloatTensor(input_data)\n    test_tensor = torch.FloatTensor(test_data)\n    \n     # Create our custom dataset with input and corresponding targets\n    train_dataset = TensorDataset(input_tensor, target_tensor)\n    \n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n    # No need to create multiple batches for the test loader\n    test_loader = DataLoader(test_tensor, batch_size=len(test_data))\n    \n    return train_loader, test_loader\n    \n    \n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 64\ntrain_loader, test_loader = batch_data(batch_size, X, y, X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check our data loader\ndata_iter = iter(train_loader)\nsample_x, sample_y = data_iter.next()\n\nprint(sample_x.shape)\nprint(sample_x)\nprint()\nprint(sample_y.shape)\nprint(sample_y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Building the Linear Regression Model\n\nNow that everything is looking good, let's build our training model!","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"\nclass LinearRegression(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.fc1 = nn.Linear(6, 128)\n        self.fc2 = nn.Linear(128, 1)\n        \n    def forward(self, x):\n        x = F.relu(self.fc1(x))\n        x = self.fc2(x)\n        return x\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"linear_regression_model = LinearRegression()\nprint(linear_regression_model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Initialize the loss and opimization functions\nlr = 0.003\ncriterion = nn.MSELoss() # mean square error\noptimizer = torch.optim.SGD(linear_regression_model.parameters(), lr=lr)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Training the Model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_model(model, epochs, cost_function, print_every = 10):\n    losses =[]\n    trained_model = None\n    for e in range(epochs):\n        train_loss = 0\n        for batch_i, (inputs, labels) in enumerate(train_loader, 1):\n        \n            optimizer.zero_grad()\n            y_pred = model(inputs)\n            loss = cost_function(y_pred, labels)\n            \n             # Perform the backpropagation and the optimization step\n            loss.backward()\n            optimizer.step()\n            \n            train_loss += loss.item() * batch_size\n        \n        train_loss = train_loss/len(train_loader.sampler)\n        losses.append(train_loss)\n            \n        if epochs % print_every == 0:\n            print(\"Epoch: {} || Loss: {}\".format(e, train_loss))\n        \n        trained_model = model\n           \n    return losses, trained_model\n \n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"losses,  linear_regression_model = train_model(linear_regression_model, 100, criterion)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Testing","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# getting a batch from testing data\nwith torch.no_grad():\n    for data in test_loader:\n        output = linear_regression_model(data)\n        preds = torch.round(output)\n    preds = preds.squeeze()\n    survived = preds.numpy()\n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"survived.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.DataFrame({'PassengerId': test_data['PassengerId'], 'Survived': survived})\nsubmission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"submission.csv\")\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"## Building the Classification  Model\n- The number of output here will change into 2\n- We'll use CrossEntropyLoss instead of MSELoss","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_loader, test_loader = batch_data(64, X, y, X_test, train_type=\"classification\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nclass Clasification(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.fc1 = nn.Linear(6, 512)\n        self.fc2 = nn.Linear(512, 512)\n        self.fc3 = nn.Linear(512, 2)\n        self.dropout = nn.Dropout(0.2)\n        \n    def forward(self, x):\n        x = self.dropout(F.relu(self.fc1(x)))\n        x = self.dropout(F.relu(self.fc2(x)))\n        x = self.fc3(x)\n        return x\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classification_model = Clasification()\nclassification_model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Initialize the loss and opimization functions\nlr = 0.0005\ncriterion = nn.CrossEntropyLoss() # mean square error\noptimizer = torch.optim.SGD(classification_model.parameters(), lr=lr, momentum=0.9)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"losses, classification_model = train_model(classification_model, 1000, criterion)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Testing & Submision\nHere I'll test the classification model and save the submission","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# getting a batch from testing data\nwith torch.no_grad():\n    for data in test_loader:\n        output = classification_model(data.float())\n        _, preds = torch.max(output.data, 1)\nsurvived = preds.numpy()  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.DataFrame({'PassengerId': test_data['PassengerId'], 'Survived': survived})\nsubmission.to_csv('submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"submission.csv\")\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}